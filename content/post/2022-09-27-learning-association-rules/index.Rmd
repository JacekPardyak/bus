---
title: Learning association rules in an Iris dataset with Spark
author: JG Pardyak
date: '2022-09-27'
slug: learning-association-rules
categories: []
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

# The question

Can we apply Frequent Pattern Mining in Apache Spark to the Iris dataset?


```{r}
library(tidyverse)
library(sparklyr)
sc <- spark_connect(master = "local")

connection_is_open(sc)
```

We start from uploading a local data frame into a remote data source. Each line is given a unique identifier to facilitate creation of the Items column.

```{r}
iris_tbl <- iris %>% 
  copy_to(sc, df = ., overwrite = TRUE) %>%
  sdf_with_sequential_id(id = "id", from = 1L)

iris_tbl %>% show()

```
 

Each numeric column is discretized with breaks specified through the splits parameter.
For better readability, classes {0, 1, 2} have been renamed {low, medium, high}.

```{r}
iris_tbl <- iris_tbl %>%
  ft_bucketizer(
    input_col = "Sepal_Length",
    output_col = "Sepal_Length_",
    splits = c(4.3, 5.5, 6.7, 7.9)
  ) %>%
  ft_bucketizer(
    input_col = "Sepal_Width",
    output_col = "Sepal_Width_",
    splits = c(2, 2.8, 3.6, 4.4)
  ) %>%
  ft_bucketizer(
    input_col = "Petal_Length",
    output_col = "Petal_Length_",
    splits = c(0.994, 2.97, 4.93, 6.91)
  ) %>%
  ft_bucketizer(
    input_col = "Petal_Width",
    output_col = "Petal_Width_",
    splits = c(0.0976, 0.9, 1.7, 2.5)
  ) %>%
  select(id, Sepal_Length_, Sepal_Width_, Petal_Length_, Petal_Width_, Species) %>%
  rename(Sepal_Length = Sepal_Length_) %>%
  rename(Sepal_Width = Sepal_Width_) %>%
  rename(Petal_Length = Petal_Length_) %>%
  rename(Petal_Width = Petal_Width_) %>%
  mutate(Sepal_Length = if_else(Sepal_Length == 0, "low", if_else(Sepal_Length == 1, "medium", "high"))) %>%
  mutate(Sepal_Width = if_else(Sepal_Width == 0, "low", if_else(Sepal_Width == 1, "medium", "high"))) %>%
  mutate(Petal_Length = if_else(Petal_Length == 0, "low", if_else(Petal_Length == 1, "medium", "high"))) %>%
  mutate(Petal_Width = if_else(Petal_Width == 0, "low", if_else(Petal_Width == 1, "medium", "high"))) %>%
  pivot_longer(!id) %>% 
  mutate(item = paste(name, "=", value)) %>% 
  group_by(id) %>%
  summarise(items = collect_list(item))
```

Lets examine the Spark table

```{r}
iris_tbl %>% show()
iris_tbl %>% filter(id == 1) %>% select(items) %>% pull() %>% unlist()
```

Now it is time to run a parallel FP-growth algorithm to mine frequent itemsets.

```{r}
model <- ml_fpgrowth(x = iris_tbl,
                     min_confidence = 0.8,
                     min_support = 0.3)
```

Here are the association rules:

```{r}
arules <- ml_association_rules(model) %>% collect() %>% 
  rowwise() %>% mutate(antecedent = paste(unlist(antecedent), collapse = ", ")) %>%
  rowwise() %>% mutate(consequent = unlist(consequent))
arules
```

And here the frequent itemsets:

```{r}
fitems <- ml_freq_itemsets(model) %>% collect() %>%
  rowwise() %>% mutate(items = paste(unlist(items), collapse = ", "))
fitems

```

